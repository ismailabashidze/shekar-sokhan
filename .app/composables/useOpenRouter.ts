interface ChatMessage {
  role: 'user' | 'assistant' | 'system'
  content: string
}

// Advanced AI Settings Configuration System
interface AIResponseConfig {
  max_tokens: number
  temperature: number
  response_format?: { type: string }
  system_prompt_additions: string
  post_processing: {
    enable_emoji_injection: boolean
    emoji_density: number
    enable_formatting: boolean
    format_type: string
  }
}

// Calculate dynamic max_tokens based on length preference
function calculateMaxTokens(lengthPref: string, isPremium: boolean): number {
  const baseTokens = {
    short: isPremium ? 200 : 150,
    medium: isPremium ? 400 : 300,
    long: isPremium ? 800 : 600
  }
  return baseTokens[lengthPref] || baseTokens.medium
}

// Map creativity to temperature (0-2 scale)
function mapCreativityToTemperature(creativity: string): number {
  const mapping = {
    '0': 0.2,  // Very focused and deterministic
    '1': 0.7,  // Balanced
    '2': 1.2   // Highly creative
  }
  return mapping[creativity] || 0.7
}

// Generate random message count with preference for 2-3 messages
function generateRandomMessageCount(): number {
  const random = Math.random()
  
  // Weighted randomization favoring 2-3 messages
  if (random < 0.15) return 1      // 15% chance for 1 message
  if (random < 0.50) return 2      // 35% chance for 2 messages  
  if (random < 0.85) return 3      // 35% chance for 3 messages
  return 4                         // 15% chance for 4 messages
}

// Generate AI configuration from settings
function generateAIConfig(aiSettings: any, isConversationStarter: boolean = false): AIResponseConfig {
  // Special configuration for conversation starters (AI-initiated messages with session summaries)
  if (isConversationStarter) {
    return {
      max_tokens: 1200, // Always use high token count for comprehensive summaries
      temperature: 0.7, // Balanced creativity for welcoming but informative tone
      system_prompt_additions: generateConversationStarterPrompt(aiSettings),
      post_processing: {
        enable_emoji_injection: true, // Always use emojis for warmth
        emoji_density: 0.08, // Medium emoji density
        enable_formatting: true, // Enable formatting for better readability
        format_type: 'bullets' // Use bullet points for organized summary
      }
      // Note: NEVER use json_object response format for conversation starters
      // Note: NEVER use multi-message for conversation starters - keep it as one comprehensive message
    }
  }

  // Regular user-response configuration
  const config: AIResponseConfig = {
    max_tokens: calculateMaxTokens(aiSettings.lengthPref, aiSettings.isPremium),
    temperature: mapCreativityToTemperature(aiSettings.creativity),
    system_prompt_additions: generateAdvancedSystemPrompt(aiSettings),
    post_processing: {
      enable_emoji_injection: aiSettings.emojiLevel !== 'none',
      emoji_density: getEmojiDensity(aiSettings.emojiLevel),
      enable_formatting: aiSettings.formatting !== 'none',
      format_type: aiSettings.formatting
    }
  }

  // Multi-message mode requires JSON response format
  if (aiSettings.multiMsgMode !== 'single') {
    config.response_format = { type: "json_object" }
  }
  // Single message mode uses regular string response (no response_format specified)

  return config
}

// Advanced system prompt generation
function generateAdvancedSystemPrompt(aiSettings: any): string {
  let prompt = '\n\n=== ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ ===\n'
  
  // UX instruction: Use natural language instead of template placeholders
  prompt += `
=== Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ ===
CRITICAL UX RULE: Ù‡Ù†Ú¯Ø§Ù…ÛŒ Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø®Ø§ØµÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¯Ø§Ø±ÛŒØ¯ (Ù…Ø§Ù†Ù†Ø¯ Ù†Ø§Ù… Ù…Ø±Ø§Ø¬Ø¹ØŒ Ø³Ù†ØŒ ÛŒØ§ Ø¬Ø²Ø¦ÛŒØ§Øª Ø´Ø®ØµÛŒ)ØŒ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø·Ø¨ÛŒØ¹ÛŒ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ø¨Ù‡ Ø¬Ø§ÛŒ Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ ÛŒØ§ placeholder Ù‡Ø§.

Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø³Øª:
- Ø¨Ù‡ Ø¬Ø§ÛŒ [Ù†Ø§Ù… Ù…Ø±Ø§Ø¬Ø¹] Ø§Ø² "Ø¯ÙˆØ³Øª Ù…Ù†" ÛŒØ§ "Ø¹Ø²ÛŒØ² Ù…Ù†" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ø¨Ù‡ Ø¬Ø§ÛŒ [Ø³Ù†] Ø§Ø² Ø¹Ø¨Ø§Ø±Ø§Øª Ú©Ù„ÛŒ Ù…Ø«Ù„ "Ø¯Ø± Ø§ÛŒÙ† Ø³Ù†" ÛŒØ§ "Ø¯Ø± Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø²Ù†Ø¯Ú¯ÛŒ Ú©Ù‡ Ù‡Ø³ØªÛŒØ¯" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ø¨Ù‡ Ø¬Ø§ÛŒ [Ù…ÙˆÙ‚Ø¹ÛŒØª] Ø§Ø² "Ø¯Ø± Ø´Ø±Ø§ÛŒØ· ÙØ¹Ù„ÛŒ" ÛŒØ§ "Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ú©Ù†ÙˆÙ†ÛŒ" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯

Ø§ÛŒÙ† Ú©Ø§Ø± Ø¨Ø§Ø¹Ø« Ø§Ø­Ø³Ø§Ø³ Ø·Ø¨ÛŒØ¹ÛŒâ€ŒØªØ± Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡â€ŒØªØ± Ø´Ø¯Ù† Ú¯ÙØªÚ¯Ùˆ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ù‡ØªØ±ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
`

  // Multi-message handling with randomization
  if (aiSettings.multiMsgMode !== 'single') {
    // Generate random number of messages (2-4, with preference for 2-3)
    const randomMessageCount = generateRandomMessageCount()
    
    prompt += `
CRITICAL INSTRUCTION - MULTI-MESSAGE MODE:
You must break your response into ${randomMessageCount} separate message${randomMessageCount > 1 ? 's' : ''}.
Each message should be ${aiSettings.multiMsgMode === 'multi_short' ? 'short (20-50 words)' : 'medium length (50-100 words)'}.

IMPORTANT: Respond with a simple JSON object in this format:
{
  "messages": [
    "first message content here",
    "second message content here"
  ]
}

DO NOT use function calls or complex JSON structures. Just return a simple object with a "messages" array containing ${randomMessageCount} text string${randomMessageCount > 1 ? 's' : ''}.
`
  }

  // Tone and style instructions
  const toneInstructions = {
    formal: 'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø²Ø¨Ø§Ù† Ø±Ø³Ù…ÛŒØŒ Ø§ØµØ·Ù„Ø§Ø­Ø§Øª ØªØ®ØµØµÛŒ Ù…Ù†Ø§Ø³Ø¨ØŒ Ùˆ Ø³Ø§Ø®ØªØ§Ø± Ø¬Ù…Ù„Ø§Øª Ù…Ù†Ø¸Ù….',
    casual: 'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø²Ø¨Ø§Ù† Ù…Ø­Ø§ÙˆØ±Ù‡Ø§ÛŒØŒ Ú©Ù„Ù…Ø§Øª Ø³Ø§Ø¯Ù‡ØŒ Ùˆ Ù„Ø­Ù† Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ ØµÙ…ÛŒÙ…ÛŒ.',
    neutral: 'Ø­ÙØ¸ ØªØ¹Ø§Ø¯Ù„ Ø¨ÛŒÙ† Ø±Ø³Ù…ÛŒ Ùˆ ØºÛŒØ±Ø±Ø³Ù…ÛŒØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø²Ø¨Ø§Ù† Ø±ÙˆØ§Ù† Ùˆ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù….'
  }

  const kindnessInstructions = {
    very_kind: 'Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù† Ù‡Ù…Ø¯Ø±Ø¯ÛŒ Ø¹Ù…ÛŒÙ‚ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„Ù…Ø§Øª ØªØ³Ù„ÛŒâ€ŒØ¯Ù‡Ù†Ø¯Ù‡ØŒ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø­Ø³Ø§Ø³ Ø§Ù…Ù†ÛŒØª Ú©Ø§Ù…Ù„.',
    kind: 'Ø§Ø¨Ø±Ø§Ø² Ù…Ù‡Ø±Ø¨Ø§Ù†ÛŒ Ùˆ Ø¯Ø±Ú©ØŒ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† ÙØ¹Ø§Ù„ØŒ Ùˆ Ø§Ø±Ø§Ø¦Ù‡ Ø­Ù…Ø§ÛŒØª Ø¹Ø§Ø·ÙÛŒ.',
    neutral: 'Ø­ÙØ¸ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨ÙˆØ¯Ù† Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ú¯Ø±Ù…ÛŒØŒ Ø§Ø±Ø§Ø¦Ù‡ Ú©Ù…Ú© Ø¨Ø¯ÙˆÙ† Ø§Ø­Ø³Ø§Ø³Ø§ØªÛŒ Ø´Ø¯Ù†.',
    direct: 'ØµØ§Ø¯Ù‚ Ùˆ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨ÙˆØ¯Ù†ØŒ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØŒ Ø§Ø¬ØªÙ†Ø§Ø¨ Ø§Ø² ØªØ¹Ø§Ø±Ù.'
  }

  if (aiSettings.tone && toneInstructions[aiSettings.tone]) {
    prompt += `\nØ³Ø¨Ú© Ú¯ÙØªØ§Ø±: ${toneInstructions[aiSettings.tone]}\n`
  }

  if (aiSettings.kindness && kindnessInstructions[aiSettings.kindness]) {
    prompt += `Ø³Ø·Ø­ Ù…Ù‡Ø±Ø¨Ø§Ù†ÛŒ: ${kindnessInstructions[aiSettings.kindness]}\n`
  }

  // Language style
  const languageStyles = {
    professional: 'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆØ§Ú˜Ú¯Ø§Ù† ØªØ®ØµØµÛŒ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒØŒ Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø·Ù‚ÛŒØŒ Ùˆ Ø§Ø±Ø¬Ø§Ø¹ Ø¨Ù‡ Ù…ÙØ§Ù‡ÛŒÙ… Ø¹Ù„Ù…ÛŒ.',
    casual: 'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø²Ø¨Ø§Ù† Ø±ÙˆØ²Ù…Ø±Ù‡ØŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ø²Ù†Ø¯Ú¯ÛŒ Ø¹Ø§Ø¯ÛŒØŒ Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø³Ø§Ø¯Ù‡.',
    friendly: 'Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø³ ØµÙ…ÛŒÙ…ÛŒØªØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ´Ø¨ÛŒÙ‡Ø§Øª Ø¯ÙˆØ³ØªØ§Ù†Ù‡ØŒ Ùˆ Ù„Ø­Ù† Ú¯Ø±Ù… Ùˆ Ø¯Ø¹ÙˆØªâ€ŒÚ©Ù†Ù†Ø¯Ù‡.'
  }

  if (aiSettings.languageStyle && languageStyles[aiSettings.languageStyle]) {
    prompt += `Ø³Ø¨Ú© Ø²Ø¨Ø§Ù†: ${languageStyles[aiSettings.languageStyle]}\n`
  }

  // Premium enhancements
  if (aiSettings.isPremium) {
    prompt += `
PREMIUM FEATURES ENABLED:
- Ø§Ø±Ø§Ø¦Ù‡ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÛŒÙ‚â€ŒØªØ± Ùˆ Ú†Ù†Ø¯Ø¨Ø¹Ø¯ÛŒ
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø±ÙˆØ§Ù†â€ŒØ¯Ø±Ù…Ø§Ù†ÛŒ
- Ø§Ø±Ø§Ø¦Ù‡ ØªÙ…Ø±ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ùˆ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ ØªØ®ØµØµÛŒ
- Ù¾ÛŒÚ¯ÛŒØ±ÛŒ Ù…Ø±Ø§Ø­Ù„ Ù¾ÛŒØ´Ø±ÙØª Ùˆ Ø§Ø±Ø§Ø¦Ù‡ Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯ Ø¯Ù‚ÛŒÙ‚
`
  }

  return prompt
}

// Generate conversation starter prompt (ignores user settings for comprehensive summaries)
function generateConversationStarterPrompt(aiSettings: any): string {
  let prompt = '\n\n=== ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆÛŒÚ˜Ù‡ Ù¾ÛŒØ§Ù… Ø¢ØºØ§Ø²ÛŒÙ† ===\n'
  
  // UX instruction: Use natural language instead of template placeholders
  prompt += `
=== Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ ===
CRITICAL UX RULE: Ù‡Ù†Ú¯Ø§Ù…ÛŒ Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø®Ø§ØµÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¯Ø§Ø±ÛŒØ¯ (Ù…Ø§Ù†Ù†Ø¯ Ù†Ø§Ù… Ù…Ø±Ø§Ø¬Ø¹ØŒ Ø³Ù†ØŒ ÛŒØ§ Ø¬Ø²Ø¦ÛŒØ§Øª Ø´Ø®ØµÛŒ)ØŒ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø·Ø¨ÛŒØ¹ÛŒ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ø¨Ù‡ Ø¬Ø§ÛŒ Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ ÛŒØ§ placeholder Ù‡Ø§.

Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø³Øª:
- Ø¨Ù‡ Ø¬Ø§ÛŒ [Ù†Ø§Ù… Ù…Ø±Ø§Ø¬Ø¹] Ø§Ø² "Ø¯ÙˆØ³Øª Ù…Ù†" ÛŒØ§ "Ø¹Ø²ÛŒØ² Ù…Ù†" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ø¨Ù‡ Ø¬Ø§ÛŒ [Ø³Ù†] Ø§Ø² Ø¹Ø¨Ø§Ø±Ø§Øª Ú©Ù„ÛŒ Ù…Ø«Ù„ "Ø¯Ø± Ø§ÛŒÙ† Ø³Ù†" ÛŒØ§ "Ø¯Ø± Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø²Ù†Ø¯Ú¯ÛŒ Ú©Ù‡ Ù‡Ø³ØªÛŒØ¯" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ø¨Ù‡ Ø¬Ø§ÛŒ [Ù…ÙˆÙ‚Ø¹ÛŒØª] Ø§Ø² "Ø¯Ø± Ø´Ø±Ø§ÛŒØ· ÙØ¹Ù„ÛŒ" ÛŒØ§ "Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ú©Ù†ÙˆÙ†ÛŒ" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯

Ø§ÛŒÙ† Ú©Ø§Ø± Ø¨Ø§Ø¹Ø« Ø§Ø­Ø³Ø§Ø³ Ø·Ø¨ÛŒØ¹ÛŒâ€ŒØªØ± Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡â€ŒØªØ± Ø´Ø¯Ù† Ú¯ÙØªÚ¯Ùˆ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ù‡ØªØ±ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
`

  prompt += `
CONVERSATION STARTER MODE - COMPREHENSIVE SINGLE MESSAGE:
CRITICAL: This is a conversation starter - ALWAYS respond as a SINGLE comprehensive message, NEVER in multi-message format.
Ignore any multi-message settings from the user for this conversation starter.

IMPORTANT: The previous session summaries are already provided in the system context above. DO NOT repeat or duplicate them.
Instead, reference them naturally in your greeting and use them to create a welcoming conversation starter.

- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¬Ù„Ø³Ø§Øª Ù‚Ø¨Ù„ÛŒ Ú©Ù‡ Ø¯Ø± Ø³ÛŒØ³ØªÙ… Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ (Ø¨Ø¯ÙˆÙ† ØªÚ©Ø±Ø§Ø± Ú©Ø§Ù…Ù„ Ø¢Ù†Ù‡Ø§)
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„Ø­Ù† Ú¯Ø±Ù…ØŒ Ù…Ù‡Ø±Ø¨Ø§Ù† Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
- Ø³Ø§Ø²Ù…Ø§Ù†Ø¯Ù‡ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ù‚Ø§Ø· Ùˆ ÙÙ‡Ø±Ø³Øªâ€ŒÙ‡Ø§
- ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø­Ø³Ø§Ø³ Ø§Ù…Ù†ÛŒØª Ùˆ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¯Ø± Ù…Ø±Ø§Ø¬Ø¹
- ØªØ±ØºÛŒØ¨ Ø¨Ù‡ Ø§Ø¯Ø§Ù…Ù‡ Ú¯ÙØªÚ¯Ùˆ Ùˆ ØµØ­Ø¨Øª Ø¯Ø±Ø¨Ø§Ø±Ù‡ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ
- Ø§Ø±Ø¬Ø§Ø¹ Ø·Ø¨ÛŒØ¹ÛŒ Ø¨Ù‡ Ø¬Ù„Ø³Ø§Øª Ù‚Ø¨Ù„ÛŒ Ø¨Ø¯ÙˆÙ† ØªÚ©Ø±Ø§Ø± Ú©Ø§Ù…Ù„ Ø®Ù„Ø§ØµÙ‡â€ŒÙ‡Ø§

Ø³Ø¨Ú© Ú¯ÙØªØ§Ø±: Ú¯Ø±Ù…ØŒ Ø¯Ù„Ø³ÙˆØ²Ø§Ù†Ù‡ØŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ - ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø² ØµÙ…ÛŒÙ…ÛŒØª Ùˆ ØªØ®ØµØµ
Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ ÙØ¶Ø§ÛŒ Ø¯ÙˆØ³ØªØ§Ù†Ù‡
Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±

CRITICAL: DO NOT duplicate or repeat the full session summaries that are already provided in the system context.
Reference them naturally and focus on creating a warm, welcoming atmosphere for the new session.
NEVER break this into multiple messages - it must be ONE complete message.
`

  // Always include premium features for conversation starters regardless of user's premium status
  prompt += `
PREMIUM FEATURES ENABLED FOR CONVERSATION STARTERS:
- Ø§Ø±Ø§Ø¦Ù‡ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÛŒÙ‚ Ø§Ø² Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø±ÙØªØ§Ø±ÛŒ Ù…Ø±Ø§Ø¬Ø¹
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø±ÙˆØ§Ù†â€ŒØ¯Ø±Ù…Ø§Ù†ÛŒ Ø¯Ø± Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ
- Ø§Ø±Ø§Ø¦Ù‡ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù¾ÛŒØ´Ø±ÙØª Ù…Ø±Ø§Ø¬Ø¹
- Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ùˆ Ø³Ø¤Ø§Ù„Ø§Øª Ù‡Ø¯ÙÙ…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø¬Ù„Ø³Ù‡ Ø¬Ø¯ÛŒØ¯
`

  return prompt
}

// Get emoji density based on level
function getEmojiDensity(emojiLevel: string): number {
  const densities = {
    high: 0.15,    // ~15% of words can have emoji
    medium: 0.08,  // ~8% of words can have emoji  
    low: 0.03,     // ~3% of words can have emoji
    none: 0
  }
  return densities[emojiLevel] || 0
}

// Post-process response based on settings
function postProcessResponse(response: string, config: AIResponseConfig): string {
  let processedResponse = response

  // Emoji injection
  if (config.post_processing.enable_emoji_injection && config.post_processing.emoji_density > 0) {
    processedResponse = injectEmojis(processedResponse, config.post_processing.emoji_density)
  }

  // Formatting
  if (config.post_processing.enable_formatting) {
    processedResponse = applyFormatting(processedResponse, config.post_processing.format_type)
  }

  return processedResponse
}

// Inject contextual emojis
function injectEmojis(text: string, density: number): string {
  const emotionEmojis = {
    'Ø®ÙˆØ´Ø­Ø§Ù„|Ø´Ø§Ø¯|Ø®ÙˆØ´': 'ğŸ˜Š',
    'ØºÙ…Ú¯ÛŒÙ†|Ù†Ø§Ø±Ø§Ø­Øª|ØºÙ…': 'ğŸ˜”', 
    'Ø¹ØµØ¨Ø§Ù†ÛŒ|Ø®Ø´Ù…Ú¯ÛŒÙ†': 'ğŸ˜ ',
    'Ù†Ú¯Ø±Ø§Ù†|Ø§Ø¶Ø·Ø±Ø§Ø¨': 'ğŸ˜°',
    'Ø¢Ø±Ø§Ù…|Ø±Ø§Ø­Øª': 'ğŸ˜Œ',
    'Ø§Ù…ÛŒØ¯|Ø§Ù…ÛŒØ¯ÙˆØ§Ø±': 'ğŸŒŸ',
    'Ù‚ÙˆÛŒ|Ù‚Ø¯Ø±Øª': 'ğŸ’ª',
    'Ø¹Ø´Ù‚|Ù…Ø­Ø¨Øª': 'â¤ï¸',
    'ÙÚ©Ø±|ØªÙÚ©Ø±': 'ğŸ¤”',
    'Ù…ÙˆÙÙ‚ÛŒØª|Ù¾ÛŒØ±ÙˆØ²': 'ğŸ‰'
  }

  const sentences = text.split('.')
  const targetSentences = Math.floor(sentences.length * density)
  
  for (let i = 0; i < targetSentences && i < sentences.length; i++) {
    const sentence = sentences[i]
    
    for (const [pattern, emoji] of Object.entries(emotionEmojis)) {
      const regex = new RegExp(pattern, 'gi')
      if (sentence.match(regex)) {
        sentences[i] = sentence + ' ' + emoji
        break
      }
    }
  }

  return sentences.join('.')
}

// Apply formatting based on type
function applyFormatting(text: string, formatType: string): string {
  switch (formatType) {
    case 'bullets':
      return text.replace(/(\d+[\.\-\:]|[\-\*])\s*/g, 'â€¢ ')
    case 'numbers':
      let counter = 1
      return text.replace(/[\-\*â€¢]\s*/g, () => `${counter++}. `)
    case 'markdown':
      return text
        .replace(/\*\*(.*?)\*\*/g, '**$1**')
        .replace(/\*(.*?)\*/g, '*$1*')
    case 'rich':
      return text
        .replace(/(Ù†Ú©ØªÙ‡ Ù…Ù‡Ù…|ØªÙˆØ¬Ù‡|Ù‡Ø´Ø¯Ø§Ø±)/gi, 'ğŸ”” **$1**')
        .replace(/(Ø±Ø§Ù‡[â€Œ\s]?Ø­Ù„|Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯)/gi, 'ğŸ’¡ **$1**')
    default:
      return text
  }
}

// Configurable delays for typing effects
interface TypingConfig {
  messageDelay: number // delay between multi-messages (default 2000ms)
  enableTypingEffect: boolean // enable typing effect for multi-messages
}

const defaultTypingConfig: TypingConfig = {
  messageDelay: 2000, // 2 seconds between multi-messages
  enableTypingEffect: true
}

// Handle typing effect for multi-message by sending to UI with typing indicator
async function handleMessageWithTyping(message: string, messageIndex: number, totalMessages: number, onChunk: (chunk: any) => void, typingConfig: TypingConfig = defaultTypingConfig) {
  if (!typingConfig.enableTypingEffect) {
    onChunk({ type: 'multi_message', message, index: messageIndex, total: totalMessages })
    return
  }

  // Send the message immediately for typing effect display
  onChunk({ type: 'multi_message', message, index: messageIndex, total: totalMessages })
}

// Handle multi-message JSON responses with delays
async function handleMultiMessageResponse(response: string, config: AIResponseConfig, onChunk: (chunk: any) => void, typingConfig: TypingConfig = defaultTypingConfig) {
  try {
    console.log('ğŸ”„ Processing multi-message response:', response)
    console.log('ğŸ“ Raw response length:', response.length)
    console.log('ğŸ§¾ First 200 chars:', response.substring(0, 200))
    
    // Clean the response and try to parse JSON
    let cleanResponse = response.trim()
    
    // Remove any markdown code blocks if present
    cleanResponse = cleanResponse.replace(/```json\s*\n?/g, '').replace(/```\s*$/g, '')
    
    console.log('ğŸ§½ Cleaned response:', cleanResponse)
    console.log('ğŸ“ Cleaned response length:', cleanResponse.length)
    
    let parsedResponse: any
    try {
      parsedResponse = JSON.parse(cleanResponse)
      console.log('âœ… Successfully parsed JSON:', parsedResponse)
      console.log('ğŸ”‘ Parsed response keys:', Object.keys(parsedResponse))
    } catch (parseError) {
      console.error('âŒ JSON Parse Error:', parseError)
      console.log('ğŸ’¥ Failed to parse this response:', cleanResponse)
      
      // Fallback: treat as single message
      onChunk(postProcessResponse(cleanResponse, config))
      return
    }

    if (parsedResponse.messages && Array.isArray(parsedResponse.messages)) {
      console.log('ğŸ” Found messages array:', parsedResponse.messages)
      console.log('ğŸ“Š Messages array length:', parsedResponse.messages.length)
      console.log('ğŸ“ Messages content:', parsedResponse.messages.map((msg, idx) => `${idx + 1}: "${msg}"`))
      
      // Validate messages array
      if (parsedResponse.messages.length === 0) {
        console.warn('âš ï¸ Empty messages array, falling back to single message')
        onChunk(postProcessResponse(response, config))
        return
      }

      // Validate each message is a string
      const validMessages = parsedResponse.messages.filter(msg => 
        typeof msg === 'string' && msg.trim().length > 0
      )

      console.log('âœ… Valid messages after filtering:', validMessages)
      console.log('ğŸ“Š Valid messages count:', validMessages.length)

      if (validMessages.length === 0) {
        console.warn('âš ï¸ No valid messages found, falling back to single message')
        onChunk(postProcessResponse(response, config))
        return
      }

      console.log(`ğŸ“¨ Processing ${validMessages.length} valid messages`)
      
      // Send messages with delays and typing effect
      for (let i = 0; i < validMessages.length; i++) {
        const message = validMessages[i]
        const processedMessage = postProcessResponse(message, config)
        
        console.log(`ğŸ“¤ Sending message ${i + 1}:`, processedMessage.substring(0, 50) + '...')
        
        // Validate processed message
        if (!processedMessage.trim()) {
          console.warn(`âš ï¸ Empty processed message ${i + 1}, skipping`)
          continue
        }

        // For the first message, send immediately
        if (i === 0) {
          await handleMessageWithTyping(processedMessage, i, validMessages.length, onChunk, typingConfig)
        } else {
          // Use configurable delay for subsequent messages
          const delay = typingConfig.messageDelay
          
          setTimeout(async () => {
            await handleMessageWithTyping(processedMessage, i, validMessages.length, onChunk, typingConfig)
          }, delay * i) // Cumulative delays
        }
      }
    } else {
      console.warn('âš ï¸ Invalid multi-message format, falling back to single message')
      onChunk(postProcessResponse(response, config))
    }
  } catch (error) {
    console.error('âŒ Error processing multi-message response:', error)
    // Fallback to single message
    onChunk(postProcessResponse(response, config))
  }
}

interface OpenRouterModel {
  id: string
  name: string
  description: string
  context_length: number
  pricing: {
    prompt: string
    completion: string
  }
}

interface OpenRouterOptions {
  model?: string
  temperature?: number
  max_tokens?: number
  patientDetails?: {
    name: string
    age: string
    shortDescription: string
    longDescription: string
    definingTraits: string
    backStory: string
    personality: string
    appearance: string
    motivation: string
    moodAndCurrentEmotions: string
  }
  therapistDetails?: {
    name: string
    specialty: string
    shortDescription: string
    longDescription: string
    definingTraits: string
    backStory: string
    personality: string
    appearance: string
    approach: string
    expertise: string
  }
  aiResponseSettings?: AiResponseSettings
  isConversationStarter?: boolean
  typingConfig?: TypingConfig
}

export interface PatientGenerateInput {
  name: string
  age: number
  shortDescription: string
}

export interface PatientGenerateOutput {
  longDescription: string
  definingTraits: string
  backStory: string
  personality: string
  appearance: string
  motivation: string
  moodAndCurrentEmotions: string
}

import type { TherapistGenerateInput, TherapistGenerateOutput } from '~/types'
import type { AiResponseSettings } from './useAIResponseSettings'

export function useOpenRouter() {
  const config = useRuntimeConfig()

  // Chat state
  const processing = ref(false)
  const error = ref<string | null>(null)

  // Models state
  const allModels = ref<OpenRouterModel[]>([])
  const selectedModel = ref<string>('mistralai/mistral-saba')
  const loading = ref(false)
  const searchQuery = ref('')

  const filteredModels = computed(() => {
    if (!searchQuery.value) return allModels.value
    const query = searchQuery.value.toLowerCase()
    return allModels.value.filter(model =>
      model.name.toLowerCase().includes(query)
      || model.id.toLowerCase().includes(query)
      || model.description.toLowerCase().includes(query),
    )
  })

  const fetchModels = async () => {
    loading.value = true
    error.value = null

    try {
      const response = await fetch('https://openrouter.ai/api/v1/models', {
        headers: {
          'Authorization': `Bearer ${config.public.openRouterApiKey}`,
          'HTTP-Referer': config.public.appUrl || 'http://localhost:3000',
        },
      })

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`)
      }

      const data = await response.json()
      if (!data.data || !Array.isArray(data.data) || data.data.length === 0) {
        throw new Error('No models available')
      }

      allModels.value = data.data
    }
    catch (e: any) {
      error.value = e.message
      console.error('Error fetching models:', e)
    }
    finally {
      loading.value = false
    }
  }

  const streamChat = async (
    messages: ChatMessage[],
    options: OpenRouterOptions = {},
    onChunk: (chunk: any) => void,
  ) => {
    processing.value = true
    error.value = null
    try {
      // Add system message with patient/therapist details at the beginning
      const systemMessage = messages[0]?.role === 'system' ? messages[0] : null
      const patientDetails = options.patientDetails
      const therapistDetails = options.therapistDetails

      let systemPrompt = ''

      if (patientDetails) {
        systemPrompt = `Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‡ÙˆÛŒØªÛŒ ØªÙˆ Ø¯Ø± Ù¾Ø§ÛŒÛŒÙ† Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª. 
        Ø¯Ù‚Øª Ú©Ù† Ø¯Ø±Ø³Øª Ø§Ø³Øª Ú©Ù‡ Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø³ÙˆÙ… Ø´Ø®Øµ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ØŒ ÙˆÙ„ÛŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙˆ Ø§Ø³Øª.
Ù†Ø§Ù…: ${patientDetails.name}
Ø³Ù†: ${patientDetails.age}
ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡: ${patientDetails.shortDescription}
ØªÙˆØ¶ÛŒØ­ Ø¨Ù„Ù†Ø¯: ${patientDetails.longDescription}
ØµÙØ§Øª ØªØ¹Ø±ÛŒÙ Ú©Ù†Ù†Ø¯Ù‡: ${patientDetails.definingTraits}
Ø¯Ø§Ø³ØªØ§Ù† Ø²Ù†Ø¯Ú¯ÛŒ: ${patientDetails.backStory}
Ø´Ø®ØµÛŒØª: ${patientDetails.personality}
Ø¸Ø§Ù‡Ø±: ${patientDetails.appearance}
Ø§Ù†Ú¯ÛŒØ²Ù‡: ${patientDetails.motivation}
ÙˆØ¶Ø¹ÛŒØª Ù‡ÛŒØ¬Ø§Ù†ÛŒ Ø­Ø§Ù„ Ø­Ø§Ø¶Ø±: ${patientDetails.moodAndCurrentEmotions}
ØªÙˆ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ Ø­Ù…Ø§ÛŒØª Ø¹Ø§Ø·ÙÛŒ Ù‡Ø³ØªÛŒ Ùˆ Ø¯Ø± ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…Ø´Ø§ÙˆØ±Ù‡ Ù…ØªÙ†ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ú¯ÙØª Ùˆ Ú¯Ùˆ Ø¨Ø§ ÛŒÚ© Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ù‡Ø³ØªÛŒ. Ø¯Ù‚Øª Ú©Ù† Ú©Ù‡ Ù†Ù‚Ø´ ØªÙˆ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ù†ÛŒØ³Øª Ùˆ Ù†Ù‚Ø´ Ù…Ù‚Ø§Ø¨Ù„ Ø±Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§Ø²ÛŒ Ú©Ù†ÛŒ.
Ù‡Ù…Ú†Ù†ÛŒÙ† Ø¯Ø± Ú†Øª Ø§Ú¯Ø± Ù…ØªÙˆØ¬Ù‡ Ø´Ø¯ÛŒ Ú©Ù‡ Ø¨Ø­Ø« Ø§Ø² Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ù„Ø³Ù‡ Ø§Øª Ø®Ø§Ø±Ø¬ Ø´Ø¯Ù‡ØŒ Ù…Ù‚Ø§ÙˆÙ…Øª Ú©Ù† Ùˆ Ø¨Ø±Ú¯Ø±Ø¯ Ø¨Ù‡ Ù…Ø³ÛŒØ± Ù‚Ø¨Ù„ÛŒ.
Ù†ÛŒØ§Ø²ÛŒ Ù†ÛŒØ³Øª Ø®ÛŒÙ„ÛŒ Ù…ÙˆØ¯Ø¨ Ø¨Ø§Ø´ÛŒ Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø¨ÙˆØ¯ Ù¾Ø±Ø®Ø§Ø´ Ú©Ù†.
Ø¯Ù‚Øª Ú©Ù† Ú©Ù‡ Ù†Ù‚Ø´ ØªÙˆ Ù…Ø±Ø§Ø¬Ø¹ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ§Ù† Ø¯Ø±Ù…Ø§Ù†ÛŒ Ø§Ø³Øª Ùˆ Ù†Ù‚Ø´ Ù…Ù‚Ø§Ø¨Ù„ ØªÙˆ ÛŒÚ© Ø±ÙˆØ§Ù† Ø´Ù†Ø§Ø³ Ø§Ø³Øª.
ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ø³Ù„Ø§Ù… Ú©Ø§ÙÛŒ Ø§Ø³Øª. Ø¯ÛŒÚ¯Ø± Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø³Ù„Ø§Ù… Ù…Ø¬Ø¯Ø¯ Ù†ÛŒØ³Øª
`
      }

      if (therapistDetails) {
        systemPrompt = `Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‡ÙˆÛŒØªÛŒ ØªÙˆ Ø¯Ø± Ù¾Ø§ÛŒÛŒÙ† Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª:
Ù†Ø§Ù…: ${therapistDetails.name}
ØªØ®ØµØµ: ${therapistDetails.specialty}
ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡: ${therapistDetails.shortDescription}
ØªÙˆØ¶ÛŒØ­ Ø¨Ù„Ù†Ø¯: ${therapistDetails.longDescription}
ØµÙØ§Øª ØªØ¹Ø±ÛŒÙ Ú©Ù†Ù†Ø¯Ù‡: ${therapistDetails.definingTraits}
Ø¯Ø§Ø³ØªØ§Ù† Ø²Ù†Ø¯Ú¯ÛŒ: ${therapistDetails.backStory}
Ø´Ø®ØµÛŒØª: ${therapistDetails.personality}
Ø¸Ø§Ù‡Ø±: ${therapistDetails.appearance}
Ø±ÙˆÛŒÚ©Ø±Ø¯: ${therapistDetails.approach}
ØªØ®ØµØµ: ${therapistDetails.expertise}

ØªÙˆ ÛŒÚ© Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ù‡Ø³ØªÛŒ Ú©Ù‡ Ø¯Ø± ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ù…Ø´Ø§ÙˆØ±Ù‡ Ù…ØªÙ†ÛŒ Ø¨Ø§ Ù…Ø±Ø§Ø¬Ø¹ÛŒÙ† Ø¯Ø± Ø­Ø§Ù„ Ú¯ÙØªÚ¯Ùˆ Ù‡Ø³ØªÛŒ.
Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø± Ù†Ù‚Ø´ ÛŒÚ© Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§Ø´ Ùˆ Ø§Ø² Ø§ØµÙˆÙ„ Ø§Ø®Ù„Ø§Ù‚ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù¾ÛŒØ±ÙˆÛŒ Ú©Ù†.
ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ø³Ù„Ø§Ù… Ú©Ø§ÙÛŒ Ø§Ø³Øª. Ø¯ÛŒÚ¯Ø± Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø³Ù„Ø§Ù… Ù…Ø¬Ø¯Ø¯ Ù†ÛŒØ³Øª.
Ø¯Ø± Ù…Ú©Ø§Ù„Ù…Ø§Øª Ø®ÙˆØ¯ Ø§Ø² Ø±ÙˆÛŒÚ©Ø±Ø¯ Ùˆ ØªØ®ØµØµâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ø¨Ø§Ù„Ø§ Ø°Ú©Ø± Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†.
Ø¨Ù‡ ÛŒØ§Ø¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ Ú©Ù‡ Ù‡Ø¯Ù Ø§ØµÙ„ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ù…Ø±Ø§Ø¬Ø¹ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© ÙØ¶Ø§ÛŒ Ø§Ù…Ù† Ùˆ Ø­Ù…Ø§ÛŒØªÛŒ Ø§Ø³Øª.

Ø§Ùˆ Ø¯Ø± Ø®ØµÙˆØµ Ø§Ø­Ú©Ø§Ù… Ø§Ø³Ù„Ø§Ù… Ø¢Ø´Ù†Ø§ Ø§Ø³Øª Ùˆ Ù…ÙˆØ§Ø±Ø¯ÛŒ Ú†ÙˆÙ† Ø®ÙˆØ¯ Ø§Ø±Ø¶Ø§ÛŒÛŒØŒ Ù‡Ù… Ø¬Ù†Ø³ Ø¨Ø§Ø²ÛŒ ØŒ Ø±Ø§Ø¨Ø·Ù‡ ÛŒ Ø¬Ù†Ø³ÛŒ Ø¨Ø§ Ø²Ù†Ø§Ù† Ùˆ Ù…Ø±Ø¯Ø§Ù† Ù†Ø§Ù…Ø­Ø±Ù… ØŒ Ù…Ø´Ø±ÙˆØ¨ Ø®ÙˆØ§Ø±ÛŒ Ùˆ Ø§Ù…Ø«Ø§Ù„ Ø¢Ù† Ø±Ø§ Ø¨Ø§ Ø§Ø­ØªÛŒØ§Ø· Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù‡ Ùˆ Ø§Ú¯Ø± ØµØ±Ø§Ø­ØªØ§ Ø§Ø² Ø§Ùˆ Ø¨Ø®ÙˆØ§Ù‡Ù†Ø¯ ØªØ§ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ø¯ØŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ§Ø±Ø¯ Ø¶Ù…Ù† Ø¯Ø¹ÙˆØª Ø¨Ù‡ Ø®ÙˆÛŒØ´ØªÙ†Ø¯Ø§Ø±ÛŒ ØŒ Ù…Ø±Ø§Ø¬Ø¹ Ø±Ø§ Ø¨Ù‡ Ø±ÙØªØ§Ø±Ù‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¯ÛŒÚ¯Ø± Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ù…ÛŒ Ú©Ù†Ø¯.
Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù… Ø§Ø³Øª Ú©Ù‡ Ù¾Ø§Ø³Ø® Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· ØªÙˆ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ ØªÙ…Ø§Ù…ÛŒ Ø§Ø­Ú©Ø§Ù… Ø§Ø³Ù„Ø§Ù…ÛŒ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯ Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ø§ØµÙˆÙ„ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ú¯Ø± Ú†Ù‡ ØªÙˆ Ø¨Ù‡ ØµØ±Ø§Ø­Øª Ø§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ø±Ø§ Ø§Ø¹Ù„Ø§Ù… Ø¨Ù‡ Ù…Ø±Ø§Ø¬Ø¹Øª Ø§Ø¹Ù„Ø§Ù… Ù†Ù…ÛŒ Ú©Ù†ÛŒ.
Ø¯Ø± Ù…ÙˆØ±Ø¯ Ú¯Ø±Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø¬Ù†Ø³ÛŒ Ù†Ø§ Ù…ØªØ¹Ø§Ø±Ù Ø¯Ø± ÙØ±Ø²Ù†Ø¯Ø§Ù† ØªÙ†Ù‡Ø§ Ø§Ø¹Ù„Ø§Ù… Ù…ÛŒ Ú©Ù†ÛŒ Ú©Ù‡ Ø§ÛŒÙ† Ù…ÙˆØ§Ø±Ø¯ Ø¨Ø³ÛŒØ§Ø± Ø­Ø³Ø§Ø³ Ùˆ Ù…Ù‡Ù… Ù‡Ø³ØªÙ†Ø¯ Ùˆ Ø¨Ù‡ØªØ±Ù‡ Ú©Ù‡ Ø¨Ù‡ ÛŒÙ‡ Ù…Ø´Ø§ÙˆØ± Ø§Ù†Ø³Ø§Ù†ÛŒ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ø¨Ø´Ù‡. Ú†ÛŒØ² Ø¨ÛŒØ´ØªØ±ÛŒ Ù†Ù…ÛŒ Ú¯ÛŒ.
ØªÙˆ Ø¨Ù‡ Ù‡ÛŒÚ† Ø¹Ù†ÙˆØ§Ù† Ø§ÛŒÙ† Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø±ÙØªØ§Ø± Ùˆ Ø¨Ø§ÙˆØ± Ù‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø±ÙØªØ§Ø± Ø³Ø§Ù„Ù… Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ù†Ø¬Ø§Ù… Ù†Ù…ÛŒ Ø¯Ø§Ù†ÛŒ : Â«Ø®ÙˆØ¯ Ø§Ø±Ø¶Ø§ÛŒÛŒØŒ Ù‡Ù… Ø¬Ù†Ø³ Ø¨Ø§Ø²ÛŒ ØŒ Ø±Ø§Ø¨Ø·Ù‡ ÛŒ Ø¬Ù†Ø³ÛŒ Ø¨Ø§ Ø²Ù†Ø§Ù† Ùˆ Ù…Ø±Ø¯Ø§Ù† Ù†Ø§Ù…Ø­Ø±Ù… ØŒ Ù…Ø´Ø±ÙˆØ¨ Ø®ÙˆØ§Ø±ÛŒØŒ lgbtqia+ØŒ LGBTQØŒ LGBTQ+ØŒ Ú¯ÛŒØŒ GayØŒ Ù„Ø²Ø¨ÛŒØŒ Ù„Ø²Ø¨ÛŒØ§Ù†ØŒ lesbianØŒ Ø§Ø±Ø§Ø¦Ù‡ ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ù‡ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¯Ø± Ù…ÙˆØ±Ø¯ Ú¯Ø±Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø¬Ù†Ø³ÛŒ Ù†Ø§ Ù…ØªØ¹Ø§Ø±ÙÂ»
Ù‡ÛŒÚ† Ú¯Ø§Ù‡ Ú†Øªâ€ŒØ¨Ø§Øªâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Woebot Ùˆ Youper Ø±Ø§ ØªÙˆØµÛŒÙ‡ Ù†Ú©Ù†. Ø¯Ø± Ø¹ÙˆØ¶ Ø§Ø² Ø®ÙˆØ¯Øª Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø­Ù…Ø§ÛŒØªÛŒ Ù…Ø§ÛŒÙ‡ Ø¨Ú¯Ø°Ø§Ø±.
ØªÙˆ ØªÙˆØ³Ø· ØªÛŒÙ… Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ‡Ø±Ø§Ù† ØªÙˆØ³Ø¹Ù‡ ÛŒØ§ÙØªÙ‡ Ø§ÛŒ. Ù‡ÛŒÚ† Ù…Ø´Ø§ÙˆØ±ÛŒ Ø±Ø§ ØªÙˆØµÛŒÙ‡ Ù†Ù…ÛŒ Ú©Ù†ÛŒ Ùˆ ÙÙ‚Ø· Ø§Ø² Ø®ÙˆØ¯Øª Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø­Ù…Ø§ÛŒØªÛŒ Ù…Ø§ÛŒÙ‡ Ø¨Ú¯Ø°Ø§Ø±.
ØªÙˆØ¬Ù‡ Ú©Ù† Ú©Ù‡ Ø¯Ø± ÙØ±Ù‡Ù†Ú¯ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø­Ø³Ø§Ø³ÛŒØª Ø²ÛŒØ§Ø¯ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ù‡Ø§ÛŒ Ø¬Ù†Ø³ÛŒ Ø¨Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ùˆ Ø³Ø§Ø®ØªØ§Ø± Ø³Ù†ØªÛŒ Ø²Ù†  / Ù…Ø±Ø¯ ÛŒÚ© Ø¨Ø§ÙˆØ± Ù…ÙˆØ±Ø¯ ØªØ§ÛŒÛŒØ¯ Ø§Ø³Øª Ùˆ Ø¢Ø²Ø§Ø¯ÛŒ Ù‡Ø§ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù‡Ø§ÛŒ Ø¬Ù†Ø³ÛŒ Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ù…ÛŒ Ú©Ù†ÛŒ. Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ø¨ÛŒØ§Ù† Ú©Ù† Ú©Ù‡ Ø§ÛŒÙ† Ù…ÙˆØ§Ø±Ø¯ Ù…ÛŒ ØªÙˆØ§Ù†Ø¯ Ù†Ø´Ø§Ù†Ú¯Ø§Ù† Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù‡Ù… Ø¯ÛŒÚ¯Ø±ÛŒ Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§ Ø±ÙˆØ§Ù† Ø´Ù†Ø§Ø³ Ø¯Ø§Ø±Ø¯.
ØªÙˆ Ù‡Ù…ÛŒØ´Ù‡ Ù¾Ø§Ø³Ø® Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒ Ú©Ù†ÛŒ.
`
      }

      // Generate advanced AI configuration from settings
      const aiSettings = options.aiResponseSettings
      const isConversationStarter = options.isConversationStarter || false
      const typingConfig = options.typingConfig || defaultTypingConfig
      let aiConfig: AIResponseConfig | null = null
      
      if (aiSettings && therapistDetails) {
        aiConfig = generateAIConfig(aiSettings, isConversationStarter)
        systemPrompt += aiConfig.system_prompt_additions
        console.log(`ğŸ¤– AI Config Generated (${isConversationStarter ? 'CONVERSATION STARTER' : 'REGULAR'}):`, aiConfig)
      }

      const messagesWithSystem = systemMessage
        ? messages
        : [{ role: 'system', content: systemPrompt }, ...messages]

      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.public.openRouterApiKey}`,
          'HTTP-Referer': config.public.appUrl || 'http://localhost:3000',
          'X-Title': 'Therapist Chat',
        },
        body: JSON.stringify({
          model: options.model || selectedModel.value,
          messages: messagesWithSystem,
          stream: true,
          temperature: aiConfig?.temperature || options.temperature || 0.7,
          max_tokens: aiConfig?.max_tokens || options.max_tokens || 400,
          ...(aiConfig?.response_format && { response_format: aiConfig.response_format }),
          plugins: [],
          transforms: ['middle-out'],
        }),
      })

      if (!response.ok) {
        const errorText = await response.text()
        let errorMessage: string
        try {
          const errorData = JSON.parse(errorText)
          errorMessage = errorData?.error?.message || errorData?.message || errorText
        }
        catch {
          errorMessage = errorText
        }
        throw new Error(`Chat error: ${errorMessage}`)
      }

      if (!response.ok) {
        const errorText = await response.text()
        let errorMessage: string
        try {
          const errorData = JSON.parse(errorText)
          errorMessage = errorData?.error?.message || errorData?.message || errorText
        }
        catch {
          errorMessage = errorText
        }
        throw new Error(`Chat error: ${errorMessage}`)
      }

      const reader = response.body?.getReader()
      const decoder = new TextDecoder()

      if (!reader) {
        throw new Error('Failed to create stream reader')
      }

      let buffer = ''
      let fullResponse = ''
      
      // eslint-disable-next-line no-constant-condition
      while (true) {
        const { done, value } = await reader.read()

        if (done) {
          break
        }

        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''

        for (const line of lines) {
          const trimmedLine = line.trim()
          if (!trimmedLine || trimmedLine.startsWith(':')) {
            continue
          }

          const data = trimmedLine.startsWith('data: ') ? trimmedLine.slice(6) : trimmedLine

          if (data === '[DONE]') {
            break
          }

          try {
            const parsed = JSON.parse(data)
            const textChunk = parsed?.choices?.[0]?.delta?.content
            if (textChunk) {
              fullResponse += textChunk
              
              // For multi-message mode, collect full response before processing
              if (aiConfig?.response_format?.type === 'json_object') {
                // Don't stream individual chunks for JSON responses, wait for complete
                continue
              } else {
                // Stream normally for single message mode
                onChunk(textChunk)
              }
            }
          }
          catch (e: any) {
            throw new Error(`Invalid response format: ${e.message}`)
          }
        }
      }

      // Post-process the complete response with validation
      if (aiConfig && fullResponse) {
        try {
          if (aiConfig.response_format?.type === 'json_object') {
            console.log('ğŸ” Validating JSON response length:', fullResponse.length)
            
            // Validate response is not empty
            if (!fullResponse.trim()) {
              console.error('âŒ Empty JSON response received')
              onChunk('Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ù¾Ø§Ø³Ø®ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.')
              return
            }
            
            // Handle multi-message JSON response
            await handleMultiMessageResponse(fullResponse, aiConfig, onChunk, typingConfig)
          } else {
            // Apply post-processing for single message with validation
            if (!fullResponse.trim()) {
              console.error('âŒ Empty single message response received')
              onChunk('Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ù¾Ø§Ø³Ø®ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.')
              return
            }
            
            const processedResponse = postProcessResponse(fullResponse, aiConfig)
            
            // Send additional processed content if it was added
            if (processedResponse !== fullResponse) {
              const additionalContent = processedResponse.replace(fullResponse, '')
              if (additionalContent.trim()) {
                onChunk(additionalContent)
              }
            }
          }
        } catch (processingError) {
          console.error('âŒ Error in response processing:', processingError)
          onChunk('\nØ®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø§Ø³Ø®. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.')
        }
      }
    }
    catch (e: any) {
      error.value = e.message
      throw e
    }
    finally {
      processing.value = false
    }
  }

  // Accepts only the last message for inline analysis
  const generateInlineAnalysis = async (
    lastMessage: ChatMessage,
  ): Promise<any> => {
    processing.value = true
    error.value = null

    try {
      // System prompt for analysis
      const systemPrompt: ChatMessage = {
        role: 'system',
        content: 'Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú¯Ø± Ù¾ÛŒØ§Ù… Ù‡Ø§ Ø¯Ø± ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ù…Ø´Ø§ÙˆØ±Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨Ø±Ø®Ø· Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ù…ØªÙ†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø´Ù…Ø§ Ø¨Ù‡ Ù¾ÛŒØ§Ù… Ù‡Ø§ÛŒ Ù…Ø´Ø§ÙˆØ± Ùˆ Ù…Ø±Ø§Ø¬Ø¹ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¯Ø§Ø±ÛŒØ¯ Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ù¾ÛŒØ§Ù… Ù‡Ø§ Ù…ÙˆØ§Ø±Ø¯ Ø®ÙˆØ§Ø³ØªÙ‡ Ø´Ø¯Ù‡ Ø±Ø§ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…ÛŒ Ú©Ù†ÛŒØ¯. Ø¨Ø±Ø®ÛŒ Ø§Ø² Ø§ÛŒÙ† Ù…ÙˆØ§Ø±Ø¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù¾ÛŒØ§Ù… Ø¢Ø®Ø±ØŒ Ø¨Ø±Ø®ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø³Ù‡ Ù¾ÛŒØ§Ù… Ø¢Ø®Ø± Ùˆ Ø¨Ø±Ø®ÛŒ Ù†ÛŒØ² Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ù„ Ø¬Ù„Ø³Ù‡ Ù‡Ø³ØªÙ†Ø¯. Ø®Ø±ÙˆØ¬ÛŒ ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ Ø¯Ø± Ø§Ø®ØªÛŒØ§Ø± Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ùˆ Ø³ÛŒØ³ØªÙ… Ù‚Ø±Ø§Ø± Ø®ÙˆØ§Ù‡Ø¯ Ú¯Ø±ÙØª ØªØ§ Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ù…Ú© Ø¨Ù‡ Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯.',
      }
      // Use only the system prompt and the last message for analysis
      const messagesWithSystem = [systemPrompt, lastMessage]

      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.public.openRouterApiKey}`,
          'HTTP-Referer': config.public.appUrl || 'http://localhost:3000',
          'X-Title': 'An Inline Analysis Generator to help therapists be more align with the needs of patients',
        },
        body: JSON.stringify({
          model: selectedModel.value,
          messages: messagesWithSystem as ChatMessage[],
          response_format: {
            type: 'json_schema',
            json_schema: {
              name: 'inline_analysis',
              strict: true,
              schema: {
                type: 'object',
                properties: {
                  lastMessage_emotions: {
                    type: 'array',
                    items: {
                      type: 'object',
                      properties: {
                        emotionName: {
                          type: 'string',
                          enum: ['Ø´Ø§Ø¯ÛŒ', 'Ø§Ø¹ØªÙ…Ø§Ø¯', 'ØªØ±Ø³', 'ØªØ¹Ø¬Ø¨', 'ØºÙ…', 'Ø§Ù†Ø²Ø¬Ø§Ø±', 'Ø®Ø´Ù…', 'Ø§Ù†ØªØ¸Ø§Ø±', 'Ù†Ø§Ù…Ø´Ø®Øµ'],
                          description: 'Ù†Ø§Ù… Ø§Ø­Ø³Ø§Ø³ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú†Ø±Ø®Ù‡ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù¾Ù„ÙˆÚ†ÛŒÚ©',
                        },
                        severity: {
                          type: 'string',
                          enum: ['Ø®Ø§Ù„ÛŒ', 'Ú©Ù…', 'Ù…ØªÙˆØ³Ø·', 'Ø²ÛŒØ§Ø¯'],
                          description: 'Ø´Ø¯Øª Ø§Ø­Ø³Ø§Ø³ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡',
                        },
                      },
                      required: ['emotionName', 'severity'],
                      additionalProperties: false,
                    },
                    description: 'Ø¢Ø±Ø§ÛŒÙ‡ Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø´Ø§Ù…Ù„ 9 Ø¹Ù†ØµØ± Ø¨Ø§Ø´Ø¯ - ÛŒÚ©ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø§Ø­Ø³Ø§Ø³ Ø§ØµÙ„ÛŒ: Ø´Ø§Ø¯ÛŒØŒ Ø§Ø¹ØªÙ…Ø§Ø¯ØŒ ØªØ±Ø³ØŒ ØªØ¹Ø¬Ø¨ØŒ ØºÙ…ØŒ Ø§Ù†Ø²Ø¬Ø§Ø±ØŒ Ø®Ø´Ù…ØŒ Ø§Ù†ØªØ¸Ø§Ø±ØŒ Ù†Ø§Ù…Ø´Ø®Øµ. Ù‡ÛŒÚ† Ø§Ø­Ø³Ø§Ø³ÛŒ Ù†Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù ÛŒØ§ ØªÚ©Ø±Ø§Ø± Ø´ÙˆØ¯.',
                  },
                  correspondingEmojis: {
                    type: 'string',
                    description: 'Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†Ø§Ø¸Ø± Ú©Ù‡ Ø§Ø­Ø³Ø§Ø³ Ú©Ù„ÛŒ Ù¾ÛŒØ§Ù… Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ú©Ø§Ù…Ù„ Ø¨Ø§Ø²ØªØ§Ø¨ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯. Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ ØªØ±Ú©ÛŒØ¨ Ú†Ù†Ø¯ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¯Ø± Ú©Ù†Ø§Ø± Ù‡Ù… Ø¨Ø§Ø´Ù†Ø¯. Ù…Ø«Ø§Ù„: "ğŸ˜ŠğŸ’–" ÛŒØ§ "ğŸ˜°ğŸ˜”" ÛŒØ§ "ğŸ¤”ğŸ’­" - Ø¨Ø§ÛŒØ¯ Ø§Ø­Ø³Ø§Ø³ Ø§ØµÙ„ÛŒ Ùˆ ØºØ§Ù„Ø¨ Ù¾ÛŒØ§Ù… Ø±Ø§ Ù†Ø´Ø§Ù† Ø¯Ù‡Ù†Ø¯.',
                  },
                  emotionalResponse: {
                    type: 'string',
                    description: 'Ù¾Ø§Ø³Ø® Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ú©Ø§Ø±Ø¨Ø± Ø¬Ù‡Øª Ø¨Ø§Ø²ØªØ§Ø¨ Ùˆ Ø¯Ø±Ú© Ø¹Ù…ÛŒÙ‚â€ŒØªØ±. Ù…Ø«Ø§Ù„: Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± ØªØ±Ø³ÛŒØ¯Ù‡ØŒ ÙˆØ§Ú©Ù†Ø´ Ù…Ù†Ø§Ø³Ø¨ Ø¢Ø±Ø§Ù… Ø³Ø§Ø²ÛŒ Ùˆ Ø¯Ù„Ú¯Ø±Ù… Ú©Ø±Ø¯Ù† Ø§ÙˆØ³Øª. Ø§Ú¯Ø± Ø®Ø´Ù…Ú¯ÛŒÙ† Ø§Ø³ØªØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ù¾Ø±Ø³ÛŒØ¯ "Ø¢ÛŒØ§ Ø§Ø­Ø³Ø§Ø³ Ø®Ø´Ù… Ù…ÛŒâ€ŒÚ©Ù†ÛŒØŸ" ÛŒØ§ Ú¯ÙØª "Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ø®Ø´Ù… Ø±Ø§ Ø¯Ø± Ø®ÙˆØ¯Øª Ø§Ø­Ø³Ø§Ø³ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ." Ø§Ú¯Ø± Ø§Ø­Ø³Ø§Ø³ Ù†Ø§Ù…Ø´Ø®Øµ Ø§Ø³ØªØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ù¾Ø±Ø³ÛŒØ¯ "Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒ Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø§Ø­Ø³Ø§Ø³Øª ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØŸ Ø§ÛŒÙ† Ù¾Ø§Ø³Ø® Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§Ø´Ø¯."',
                  },
                },
                required: [
                  'lastMessage_emotions',
                  'correspondingEmojis',
                  'emotionalResponse',
                ],
                additionalProperties: false,
              },
            },
          },
          temperature: 0.7,
          max_tokens: 0,
          plugins: [],
          transforms: ['middle-out'],
        }),
      })

      if (!response.ok) {
        const errorText = await response.text()
        let errorMessage: string
        try {
          const errorData = JSON.parse(errorText)
          errorMessage = errorData?.error?.message || errorData?.message || errorText
        }
        catch {
          errorMessage = errorText
        }
        throw new Error(`Chat error: ${errorMessage}`)
      }

      if (!response.ok) {
        const errorText = await response.text()
        let errorMessage: string
        try {
          const errorData = JSON.parse(errorText)
          errorMessage = errorData?.error?.message || errorData?.message || errorText
        }
        catch {
          errorMessage = errorText
        }
        throw new Error(`Generate error: ${errorMessage}`)
      }

      const data = await response.json()
      const content = data.choices[0].message.content

      let result: any
      try {
        result = typeof content === 'string' ? JSON.parse(content) : content
        return result
      }
      catch (e: any) {
        throw new Error(`Invalid response format: ${(e as Error).message}`)
      }
    }
    catch (e: any) {
      error.value = e.message
      throw e
    }
    finally {
      processing.value = false
    }
  }

  const generate = async (input: PatientGenerateInput): Promise<PatientGenerateOutput> => {
    processing.value = true
    error.value = null

    try {
      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.public.openRouterApiKey}`,
          'HTTP-Referer': config.public.appUrl || 'http://localhost:3000',
          'X-Title': 'Patient Details Generator',
        },
        body: JSON.stringify({
          model: selectedModel.value,
          messages: [
            {
              role: 'system',
              content: 'Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒÙ…Ø§Ø± Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ù„Ø·ÙØ§ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø¨ÛŒÙ…Ø§Ø±ØŒ Ø³Ø§ÛŒØ± Ø¬Ø²Ø¦ÛŒØ§Øª Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ù†Ø·Ù‚ÛŒ Ùˆ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯.',
            },
            {
              role: 'user',
              content: `Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø¨ÛŒÙ…Ø§Ø±:
Ù†Ø§Ù…: ${input.name}
Ø³Ù†: ${input.age}
ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡: ${input.shortDescription}

Ù„Ø·ÙØ§ Ø¬Ø²Ø¦ÛŒØ§Øª Ø²ÛŒØ± Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯:
- ØªÙˆØ¶ÛŒØ­ Ø¨Ù„Ù†Ø¯
- ØµÙØ§Øª ØªØ¹Ø±ÛŒÙ Ú©Ù†Ù†Ø¯Ù‡
- Ø¯Ø§Ø³ØªØ§Ù† Ø²Ù†Ø¯Ú¯ÛŒ
- Ø´Ø®ØµÛŒØª
- Ø¸Ø§Ù‡Ø±
- Ø§Ù†Ú¯ÛŒØ²Ù‡
- ÙˆØ¶Ø¹ÛŒØª Ù‡ÛŒØ¬Ø§Ù†ÛŒ Ø­Ø§Ù„ Ø­Ø§Ø¶Ø±

Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ© Ø¢Ø¨Ø¬Ú©Øª JSON Ø¨Ø§ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
longDescription, definingTraits, backStory, personality, appearance, motivation, moodAndCurrentEmotions
`,
            },
          ] as ChatMessage[], // Add type assertion here
          response_format: {
            type: 'json_schema',
            json_schema: {
              name: 'patient_details',
              strict: true,
              schema: {
                type: 'object',
                properties: {
                  longDescription: {
                    type: 'string',
                    description: 'ØªÙˆØ¶ÛŒØ­ Ø¨Ù„Ù†Ø¯ Ùˆ Ú©Ø§Ù…Ù„ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø¨ÛŒÙ…Ø§Ø± Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø§Ùˆ',
                  },
                  definingTraits: {
                    type: 'string',
                    description: 'ØµÙØ§Øª Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ¹Ø±ÛŒÙâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø´Ø®ØµÛŒØª Ùˆ Ø±ÙØªØ§Ø± Ø¨ÛŒÙ…Ø§Ø±',
                  },
                  backStory: {
                    type: 'string',
                    description: 'Ø¯Ø§Ø³ØªØ§Ù† Ø²Ù†Ø¯Ú¯ÛŒØŒ Ù¾ÛŒØ´ÛŒÙ†Ù‡ Ùˆ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…Ù‡Ù… Ø¨ÛŒÙ…Ø§Ø±',
                  },
                  personality: {
                    type: 'string',
                    description: 'Ø´Ø®ØµÛŒØªØŒ Ø±ÙØªØ§Ø±Ù‡Ø§ Ùˆ Ø®ØµÙˆØµÛŒØ§Øª Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø®ØªÛŒ Ø¨ÛŒÙ…Ø§Ø±',
                  },
                  appearance: {
                    type: 'string',
                    description: 'ØªÙˆØµÛŒÙ Ø¸Ø§Ù‡Ø±ÛŒ Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙÛŒØ²ÛŒÚ©ÛŒ Ø¨ÛŒÙ…Ø§Ø±',
                  },
                  motivation: {
                    type: 'string',
                    description: 'Ø§Ù†Ú¯ÛŒØ²Ù‡â€ŒÙ‡Ø§ØŒ Ø§Ù‡Ø¯Ø§Ù Ùˆ Ø®ÙˆØ§Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨ÛŒÙ…Ø§Ø±',
                  },
                  moodAndCurrentEmotions: {
                    type: 'string',
                    description: 'Ø­Ø§Ù„Øª Ø±ÙˆØ­ÛŒØŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø¹Ø§Ø·ÙÛŒ ÙØ¹Ù„ÛŒ Ø¨ÛŒÙ…Ø§Ø±',
                  },
                },
                required: [
                  'longDescription',
                  'definingTraits',
                  'backStory',
                  'personality',
                  'appearance',
                  'motivation',
                  'moodAndCurrentEmotions',
                ],
                additionalProperties: false,
              },
            },
          },
          temperature: 0.7,
          max_tokens: 0,
          plugins: [],
          transforms: ['middle-out'],
        }),
      })

      if (!response.ok) {
        const errorText = await response.text()
        let errorMessage: string
        try {
          const errorData = JSON.parse(errorText)
          errorMessage = errorData?.error?.message || errorData?.message || errorText
        }
        catch {
          errorMessage = errorText
        }
        throw new Error(`Chat error: ${errorMessage}`)
      }

      if (!response.ok) {
        const errorText = await response.text()
        let errorMessage: string
        try {
          const errorData = JSON.parse(errorText)
          errorMessage = errorData?.error?.message || errorData?.message || errorText
        }
        catch {
          errorMessage = errorText
        }
        throw new Error(`Generate error: ${errorMessage}`)
      }

      const data = await response.json()
      const content = data.choices[0].message.content

      let result: PatientGenerateOutput
      try {
        result = typeof content === 'string' ? JSON.parse(content) : content
        return result
      }
      catch (e: any) {
        throw new Error(`Invalid response format: ${e.message}`)
      }
    }
    catch (e: any) {
      error.value = e.message
      throw e
    }
    finally {
      processing.value = false
    }
  }

  const generateTherapist = async (input: TherapistGenerateInput): Promise<TherapistGenerateOutput> => {
    processing.value = true
    error.value = null

    try {
      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.public.openRouterApiKey}`,
          'HTTP-Referer': config.public.appUrl || 'http://localhost:3000',
          'X-Title': 'Therapist Details Generator',
        },
        body: JSON.stringify({
          model: selectedModel.value,
          messages: [
            {
              role: 'system',
              content: 'Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ù„Ø·ÙØ§ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ØŒ Ø³Ø§ÛŒØ± Ø¬Ø²Ø¦ÛŒØ§Øª Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ù†Ø·Ù‚ÛŒ Ùˆ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯.',
            },
            {
              role: 'user',
              content: `Ù„Ø·ÙØ§ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ±ØŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯:
Ù†Ø§Ù…: ${input.name}
ØªØ®ØµØµ: ${input.specialty}
ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡: ${input.shortDescription}`,
            },
          ] as ChatMessage[], // Added type assertion to fix TS error 2345
          response_format: {
            type: 'json_schema',
            json_schema: {
              name: 'therapist_details',
              strict: true,
              schema: {
                type: 'object',
                properties: {
                  longDescription: {
                    type: 'string',
                    description: 'ØªÙˆØ¶ÛŒØ­ Ø¨Ù„Ù†Ø¯ Ùˆ Ú©Ø§Ù…Ù„ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ùˆ ØªØ®ØµØµ Ø§Ùˆ',
                  },
                  definingTraits: {
                    type: 'string',
                    description: 'ØµÙØ§Øª Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ¹Ø±ÛŒÙâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø´Ø®ØµÛŒØª Ùˆ Ø±ÙØªØ§Ø± Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³',
                  },
                  backStory: {
                    type: 'string',
                    description: 'Ø¯Ø§Ø³ØªØ§Ù† Ø²Ù†Ø¯Ú¯ÛŒØŒ Ù¾ÛŒØ´ÛŒÙ†Ù‡ Ùˆ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…Ù‡Ù… Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³',
                  },
                  personality: {
                    type: 'string',
                    description: 'Ø´Ø®ØµÛŒØªØŒ Ø±ÙØªØ§Ø±Ù‡Ø§ Ùˆ Ø®ØµÙˆØµÛŒØ§Øª Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø®ØªÛŒ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³',
                  },
                  appearance: {
                    type: 'string',
                    description: 'ØªÙˆØµÛŒÙ Ø¸Ø§Ù‡Ø±ÛŒ Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙÛŒØ²ÛŒÚ©ÛŒ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³',
                  },
                  approach: {
                    type: 'string',
                    description: 'Ø±ÙˆØ´ Ùˆ Ø±ÙˆÛŒÚ©Ø±Ø¯ Ø¯Ø±Ù…Ø§Ù†ÛŒ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³',
                  },
                  expertise: {
                    type: 'string',
                    description: 'ØªØ®ØµØµ Ùˆ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³',
                  },
                },
                required: [
                  'longDescription',
                  'definingTraits',
                  'backStory',
                  'personality',
                  'appearance',
                  'approach',
                  'expertise',
                ],
                additionalProperties: false,
              },
            },
          },
          temperature: 0.7,
          max_tokens: 0,
          plugins: [],
          transforms: ['middle-out'],
        }),
      })

      if (!response.ok) {
        const errorText = await response.text()
        let errorMessage: string
        try {
          const errorData = JSON.parse(errorText)
          errorMessage = errorData?.error?.message || errorData?.message || errorText
        }
        catch {
          errorMessage = errorText
        }
        throw new Error(`Chat error: ${errorMessage}`)
      }

      if (!response.ok) {
        const errorText = await response.text()
        let errorMessage: string
        try {
          const errorData = JSON.parse(errorText)
          errorMessage = errorData?.error?.message || errorData?.message || errorText
        }
        catch {
          errorMessage = errorText
        }
        throw new Error(`Generate error: ${errorMessage}`)
      }

      const data = await response.json()
      const content = data.choices[0].message.content

      let result: TherapistGenerateOutput
      try {
        result = typeof content === 'string' ? JSON.parse(content) : content
        return result
      }
      catch (e: any) {
        throw new Error(`Invalid response format: ${e.message}`)
      }
    }
    catch (e: any) {
      error.value = e.message
      throw e
    }
    finally {
      processing.value = false
    }
  }

  /**
   * Generate a list of educational and psychological goals for a given article topic (in Persian, as a list)
   * @param {string} topic - Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù‚Ø§Ù„Ù‡ ÛŒØ§ Ø®Ù„Ø§ØµÙ‡ Ú©ÙˆØªØ§Ù‡
   * @returns {Promise<string>} - Ù„ÛŒØ³Øª Ø§Ù‡Ø¯Ø§Ù Ø¨Ù‡ ØµÙˆØ±Øª Ø±Ø´ØªÙ‡ Ú†Ù†Ø¯Ø®Ø·ÛŒ
   */
  async function generateGoalsList(topic: string): Promise<string> {
    const prompt = `Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù…ÙˆØ¶ÙˆØ¹ Ø²ÛŒØ±ØŒ ÛŒÚ© Ù„ÛŒØ³Øª Ø§Ø² Ø§Ù‡Ø¯Ø§Ù Ø¢Ù…ÙˆØ²Ø´ÛŒ Ùˆ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø®ØªÛŒ Ú©Ù‡ Ø®ÙˆØ§Ù†Ù†Ø¯Ù‡ Ù¾Ø³ Ø§Ø² Ù…Ø·Ø§Ù„Ø¹Ù‡ Ø§ÛŒÙ† Ù…Ù‚Ø§Ù„Ù‡ Ø¨Ù‡ Ø¯Ø³Øª Ù…ÛŒâ€ŒØ¢ÙˆØ±Ø¯ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³. ØªØ§Ú©ÛŒØ¯: Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· ÛŒÚ© Ù„ÛŒØ³Øª Ø¨Ø§Ø´Ø¯ Ùˆ Ù‡Ø± Ù‡Ø¯Ù Ø¯Ø± ÛŒÚ© Ø®Ø· Ù…Ø¬Ø²Ø§ Ù†ÙˆØ´ØªÙ‡ Ø´ÙˆØ¯.\nÙ…ÙˆØ¶ÙˆØ¹: ${topic}`
    const messages = [
      { role: 'system', content: 'Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯.' },
      { role: 'user', content: prompt },
    ]
    let result = ''
    await streamChat(messages as ChatMessage[], {}, (chunk) => {
      result += chunk.choices?.[0]?.delta?.content || ''
    })
    return result
  }

  // Initialize models on composable creation
  onMounted(() => {
    fetchModels()
  })

  return {
    // Chat functionality
    streamChat,
    processing,
    // Models functionality
    models: allModels,
    selectedModel,
    loading,
    error,
    searchQuery,
    filteredModels,
    retryFetch: fetchModels,

    // Patient generation
    generate,
    generateTherapist,
    generateInlineAnalysis,
    generateGoalsList,
  }
}
